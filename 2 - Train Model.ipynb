{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to train a neural newtork to classify spoken words. It starts with the VGG 16 pre-trained weights. It then one by one unlocks the 16 layers to retrain the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction example\n",
    "import numpy as np\n",
    "import librosa\n",
    "from librosa import display\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y,sr=librosa.load(r'/home/ubuntu/Final/train/audio/go/004ae714_nohash_0.wav',sr=None)\n",
    "M = librosa.feature.melspectrogram(y=y,n_mels=128)\n",
    "MP=librosa.power_to_db(M, ref=np.max)\n",
    "A=librosa.feature.chroma_cqt(y,n_chroma=128)\n",
    "MA=librosa.power_to_db(M, ref=np.max)\n",
    "C = librosa.feature.mfcc(y,n_mfcc=128)\n",
    "MC = librosa.power_to_db(C, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "librosa.display.specshow(MP, y_axis='mel', x_axis='time');\n",
    "#librosa.display.waveplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(val):\n",
    "    values = np.array(val)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    encoded = np_utils.to_categorical(integer_encoded).astype(int)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features without Background Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = ['stop','two','three','happy','left','right']\n",
    "with open('No_Background_Files/go_features.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    feats = data\n",
    "with open('No_Background_Files/go_labels.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "    labs = data1\n",
    "for cmd in car:\n",
    "    with open('No_Background_Files/'+str(cmd) +'_features.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        feats = np.concatenate((feats,data))\n",
    "    with open('No_Background_Files/'+str(cmd) +'_labels.pkl', 'rb') as f:\n",
    "        data1 = pickle.load(f)\n",
    "        labs = np.concatenate((labs,data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = ['bird','cat','dog','bird','one','two','three','four','five','six'\n",
    "           ,'seven','eight','nine','zero','bird','happy','house','marvin','sheila'\n",
    "           ,'tree','wow']\n",
    "with open('No_Background_Files/unknowns/bedfeatures.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    unknown = data\n",
    "with open('No_Background_Files/unknowns/bedlabels.pkl', 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "    unknowns_labs = data1\n",
    "for cmd in unknowns:\n",
    "    with open('No_Background_Files/unknowns/'+str(cmd) +'features.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        unknown = np.concatenate((unknown,data))\n",
    "    with open('No_Background_Files/unknowns/'+str(cmd) +'labels.pkl', 'rb') as f:\n",
    "        data1 = pickle.load(f)\n",
    "        unknowns_labs = np.concatenate((unknowns_labs,data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make inputs the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((feats, np.zeros(np.shape(feats))), axis = 3)\n",
    "features = np.concatenate((features, np.zeros(np.shape(feats))), axis = 3)\n",
    "features = np.pad(features, [(0, 0),(0,0), (0, 7),(0,0)], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14962, 128, 48, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int, X_test, y_train_int, y_test = train_test_split(features,labs,test_size=0.2,random_state=2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_int,y_train_int,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'X_train.pkl'\n",
    "pickle.dump(X_train, open(filename, 'wb'))\n",
    "\n",
    "filename = 'y_train.pkl'\n",
    "pickle.dump(y_train, open(filename, 'wb'))\n",
    "\n",
    "filename = 'X_test.pkl'\n",
    "pickle.dump(X_train, open(filename, 'wb'))\n",
    "\n",
    "filename = 'y_test.pkl'\n",
    "pickle.dump(y_test, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "# note we exclude the final dense layers and add one back below, we would retrain it ourselves\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 48, 3)) \n",
    " \n",
    "# Freeze convolutional layers\n",
    "# for layer in base_model.layers[-4:]:\n",
    "#     layer.trainable = True    \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "    \n",
    "x = base_model.output\n",
    "x = Flatten()(x) # flatten from convolution tensor output \n",
    "\n",
    "densee0 = Dense(1024, activation='relu')(x)\n",
    "dd0 = Dropout(.23)(densee0)\n",
    "densee1 = Dense(512, activation='relu')(dd0)\n",
    "dd1 = Dropout(.23)(densee1)\n",
    "densee2 = Dense(256, activation='relu')(dd1)\n",
    "d0 = Dropout(.23)(densee2)\n",
    "dense1 = Dense(128, activation='relu')(d0)\n",
    "d1 = Dropout(.23)(dense1)\n",
    "dense2 = Dense(128, activation='relu')(d1)\n",
    "d2 = Dropout(.23)(dense2)\n",
    "dense3 = Dense(64, activation='relu')(d2)\n",
    "d3 = Dropout(.23)(dense3)\n",
    "dense4 = Dense(32, activation='relu')(d3)\n",
    "d4 = Dropout(.23)(dense4)\n",
    "predictions = Dense(7, activation='softmax')(d4) # should match # of classes predicted\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=.001\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 24s 2ms/step - loss: 1.9851 - acc: 0.1490 - val_loss: 1.9420 - val_acc: 0.1345\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.9337 - acc: 0.1670 - val_loss: 1.8536 - val_acc: 0.2210\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.8360 - acc: 0.2319 - val_loss: 1.7031 - val_acc: 0.2602\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.7444 - acc: 0.2632 - val_loss: 1.6731 - val_acc: 0.2870\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.7003 - acc: 0.2821 - val_loss: 1.6263 - val_acc: 0.2870\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.6805 - acc: 0.2890 - val_loss: 1.6160 - val_acc: 0.2999\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.6501 - acc: 0.2916 - val_loss: 1.6017 - val_acc: 0.3124\n",
      "Epoch 8/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.6342 - acc: 0.3040 - val_loss: 1.5746 - val_acc: 0.3141\n",
      "Epoch 9/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.6226 - acc: 0.3091 - val_loss: 1.5683 - val_acc: 0.3187\n",
      "Epoch 10/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.6102 - acc: 0.3225 - val_loss: 1.5508 - val_acc: 0.3471\n",
      "Epoch 11/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.5696 - acc: 0.3330 - val_loss: 1.5577 - val_acc: 0.3292\n",
      "Epoch 12/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.5510 - acc: 0.3393 - val_loss: 1.4763 - val_acc: 0.3713\n",
      "Epoch 13/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.5332 - acc: 0.3564 - val_loss: 1.4554 - val_acc: 0.3830\n",
      "Epoch 14/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.5078 - acc: 0.3685 - val_loss: 1.4595 - val_acc: 0.3881\n",
      "Epoch 15/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4906 - acc: 0.3732 - val_loss: 1.4500 - val_acc: 0.3864\n",
      "Epoch 16/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4836 - acc: 0.3737 - val_loss: 1.4375 - val_acc: 0.3893\n",
      "Epoch 17/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4653 - acc: 0.3828 - val_loss: 1.4510 - val_acc: 0.3947\n",
      "Epoch 18/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4558 - acc: 0.3878 - val_loss: 1.4294 - val_acc: 0.4006\n",
      "Epoch 19/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4283 - acc: 0.3872 - val_loss: 1.4047 - val_acc: 0.4152\n",
      "Epoch 20/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4330 - acc: 0.3921 - val_loss: 1.4205 - val_acc: 0.4006\n",
      "Epoch 21/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4192 - acc: 0.3967 - val_loss: 1.3907 - val_acc: 0.3972\n",
      "Epoch 22/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3994 - acc: 0.4033 - val_loss: 1.4072 - val_acc: 0.4252\n",
      "Epoch 23/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4150 - acc: 0.4062 - val_loss: 1.3883 - val_acc: 0.4277\n",
      "Epoch 24/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.4010 - acc: 0.4103 - val_loss: 1.4062 - val_acc: 0.4110\n",
      "Epoch 25/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3852 - acc: 0.4177 - val_loss: 1.3755 - val_acc: 0.4307\n",
      "Epoch 26/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3626 - acc: 0.4270 - val_loss: 1.4346 - val_acc: 0.4131\n",
      "Epoch 27/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3565 - acc: 0.4257 - val_loss: 1.3666 - val_acc: 0.4361\n",
      "Epoch 28/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3590 - acc: 0.4305 - val_loss: 1.3898 - val_acc: 0.4206\n",
      "Epoch 29/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3659 - acc: 0.4312 - val_loss: 1.3632 - val_acc: 0.4511\n",
      "Epoch 30/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3276 - acc: 0.4451 - val_loss: 1.3405 - val_acc: 0.4586\n",
      "Epoch 31/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3285 - acc: 0.4480 - val_loss: 1.3137 - val_acc: 0.4745\n",
      "Epoch 32/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3176 - acc: 0.4604 - val_loss: 1.3173 - val_acc: 0.4783\n",
      "Epoch 33/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3238 - acc: 0.4514 - val_loss: 1.3153 - val_acc: 0.4858\n",
      "Epoch 34/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3025 - acc: 0.4621 - val_loss: 1.3727 - val_acc: 0.4612\n",
      "Epoch 35/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3196 - acc: 0.4672 - val_loss: 1.3386 - val_acc: 0.4783\n",
      "Epoch 36/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.3129 - acc: 0.4642 - val_loss: 1.3337 - val_acc: 0.4829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b39a60320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = encode(y_train)\n",
    "y_val_cat = encode(y_val)\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=100, validation_data=(X_val, y_val_cat),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_layers(i,lr):\n",
    "    for layer in base_model.layers[i:]:\n",
    "        layer.trainable = True\n",
    "    optimizer = Adam(lr=lr)\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print(\"Layer: \"+str(i))\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "    model.fit(X_train, y_train_cat, batch_size=64, epochs=100, validation_data=(X_val, y_val_cat),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: -1\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.2363 - acc: 0.4960 - val_loss: 1.2940 - val_acc: 0.5084\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.2106 - acc: 0.5062 - val_loss: 1.2923 - val_acc: 0.5201\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.2024 - acc: 0.5039 - val_loss: 1.2853 - val_acc: 0.5230\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.1982 - acc: 0.5095 - val_loss: 1.2918 - val_acc: 0.5272\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.1748 - acc: 0.5191 - val_loss: 1.2834 - val_acc: 0.5167\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.1874 - acc: 0.5161 - val_loss: 1.2863 - val_acc: 0.5221\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 17s 2ms/step - loss: 1.1756 - acc: 0.5210 - val_loss: 1.2863 - val_acc: 0.5213\n",
      "Layer: -2\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 19s 2ms/step - loss: 1.4548 - acc: 0.4311 - val_loss: 1.3589 - val_acc: 0.4812\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.3551 - acc: 0.4570 - val_loss: 1.3349 - val_acc: 0.4850\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.3324 - acc: 0.4743 - val_loss: 1.3254 - val_acc: 0.5079\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 19s 2ms/step - loss: 1.2753 - acc: 0.4889 - val_loss: 1.3153 - val_acc: 0.4908\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.2646 - acc: 0.4936 - val_loss: 1.2510 - val_acc: 0.5251\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.2447 - acc: 0.5092 - val_loss: 1.2879 - val_acc: 0.5046\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.2562 - acc: 0.5001 - val_loss: 1.2235 - val_acc: 0.5347\n",
      "Epoch 8/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.2074 - acc: 0.5169 - val_loss: 1.2232 - val_acc: 0.5201\n",
      "Epoch 9/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.1884 - acc: 0.5239 - val_loss: 1.2383 - val_acc: 0.5443\n",
      "Epoch 10/100\n",
      "9575/9575 [==============================] - 19s 2ms/step - loss: 1.2095 - acc: 0.5229 - val_loss: 1.2131 - val_acc: 0.5556\n",
      "Epoch 11/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.1417 - acc: 0.5488 - val_loss: 1.1943 - val_acc: 0.5581\n",
      "Epoch 12/100\n",
      "9575/9575 [==============================] - 19s 2ms/step - loss: 1.1552 - acc: 0.5429 - val_loss: 1.1540 - val_acc: 0.5439\n",
      "Epoch 13/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.1565 - acc: 0.5486 - val_loss: 1.2122 - val_acc: 0.5347\n",
      "Epoch 14/100\n",
      "9575/9575 [==============================] - 18s 2ms/step - loss: 1.1165 - acc: 0.5571 - val_loss: 1.1622 - val_acc: 0.5794\n",
      "Layer: -3\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.4081 - acc: 0.4472 - val_loss: 1.3125 - val_acc: 0.5167\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.2963 - acc: 0.4969 - val_loss: 1.3261 - val_acc: 0.4532\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.2059 - acc: 0.5280 - val_loss: 1.1847 - val_acc: 0.5501\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 19s 2ms/step - loss: 1.1815 - acc: 0.5339 - val_loss: 1.1597 - val_acc: 0.5585\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.1553 - acc: 0.5438 - val_loss: 1.1066 - val_acc: 0.5877\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.1147 - acc: 0.5711 - val_loss: 1.1300 - val_acc: 0.5869\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.0928 - acc: 0.5775 - val_loss: 1.0692 - val_acc: 0.5927\n",
      "Epoch 8/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.0742 - acc: 0.5844 - val_loss: 1.1625 - val_acc: 0.5606\n",
      "Epoch 9/100\n",
      "9575/9575 [==============================] - 20s 2ms/step - loss: 1.0609 - acc: 0.5902 - val_loss: 1.1748 - val_acc: 0.5735\n",
      "Layer: -4\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 23s 2ms/step - loss: 1.2549 - acc: 0.5218 - val_loss: 1.1466 - val_acc: 0.5581\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 1.0958 - acc: 0.5873 - val_loss: 1.0911 - val_acc: 0.6282\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 1.0394 - acc: 0.6183 - val_loss: 0.9858 - val_acc: 0.6633\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 22s 2ms/step - loss: 0.9873 - acc: 0.6378 - val_loss: 0.9388 - val_acc: 0.6805\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 22s 2ms/step - loss: 0.9344 - acc: 0.6679 - val_loss: 0.8608 - val_acc: 0.7076\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.8981 - acc: 0.6722 - val_loss: 0.8973 - val_acc: 0.6876\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.9083 - acc: 0.6692 - val_loss: 0.9410 - val_acc: 0.6750\n",
      "Layer: -5\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 23s 2ms/step - loss: 0.8451 - acc: 0.7021 - val_loss: 0.8148 - val_acc: 0.7343\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.8265 - acc: 0.7119 - val_loss: 0.8350 - val_acc: 0.7143\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 22s 2ms/step - loss: 0.7503 - acc: 0.7410 - val_loss: 0.7361 - val_acc: 0.7561\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.6946 - acc: 0.7507 - val_loss: 0.7206 - val_acc: 0.7586\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 22s 2ms/step - loss: 0.6641 - acc: 0.7601 - val_loss: 0.7312 - val_acc: 0.7623\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.6404 - acc: 0.7801 - val_loss: 0.6863 - val_acc: 0.7719\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.5940 - acc: 0.7881 - val_loss: 0.7107 - val_acc: 0.7594\n",
      "Epoch 8/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.5927 - acc: 0.7889 - val_loss: 0.6585 - val_acc: 0.7895\n",
      "Epoch 9/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.5174 - acc: 0.8184 - val_loss: 0.6935 - val_acc: 0.7870\n",
      "Epoch 10/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.5332 - acc: 0.8198 - val_loss: 0.6303 - val_acc: 0.8020\n",
      "Epoch 11/100\n",
      "9575/9575 [==============================] - 22s 2ms/step - loss: 0.5114 - acc: 0.8209 - val_loss: 0.6504 - val_acc: 0.8058\n",
      "Epoch 12/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.4946 - acc: 0.8364 - val_loss: 0.6129 - val_acc: 0.8237\n",
      "Epoch 13/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.4537 - acc: 0.8464 - val_loss: 0.6510 - val_acc: 0.7886\n",
      "Epoch 14/100\n",
      "9575/9575 [==============================] - 21s 2ms/step - loss: 0.4567 - acc: 0.8446 - val_loss: 0.7914 - val_acc: 0.7769\n",
      "Layer: -6\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 25s 3ms/step - loss: 0.7722 - acc: 0.7361 - val_loss: 0.9887 - val_acc: 0.6504\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 24s 2ms/step - loss: 0.6867 - acc: 0.7757 - val_loss: 0.7540 - val_acc: 0.7740\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 23s 2ms/step - loss: 0.5855 - acc: 0.8123 - val_loss: 0.6325 - val_acc: 0.7953\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 24s 2ms/step - loss: 0.5204 - acc: 0.8346 - val_loss: 0.6411 - val_acc: 0.8079\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 24s 2ms/step - loss: 0.5273 - acc: 0.8287 - val_loss: 0.6989 - val_acc: 0.7836\n",
      "Layer: -7\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 28s 3ms/step - loss: 0.7936 - acc: 0.7308 - val_loss: 0.6724 - val_acc: 0.7736\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 26s 3ms/step - loss: 0.6014 - acc: 0.8030 - val_loss: 0.8826 - val_acc: 0.7673\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 26s 3ms/step - loss: 0.5949 - acc: 0.8070 - val_loss: 0.5018 - val_acc: 0.8338\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 25s 3ms/step - loss: 0.5359 - acc: 0.8284 - val_loss: 0.5988 - val_acc: 0.7987\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 26s 3ms/step - loss: 0.5388 - acc: 0.8276 - val_loss: 0.5196 - val_acc: 0.8446\n",
      "Layer: -8\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 30s 3ms/step - loss: 0.6320 - acc: 0.7925 - val_loss: 0.4762 - val_acc: 0.8480\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 27s 3ms/step - loss: 0.5383 - acc: 0.8270 - val_loss: 0.6658 - val_acc: 0.8020\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 27s 3ms/step - loss: 0.4655 - acc: 0.8528 - val_loss: 0.6183 - val_acc: 0.7974\n",
      "Layer: -9\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 29s 3ms/step - loss: 0.5171 - acc: 0.8404 - val_loss: 0.4400 - val_acc: 0.8697\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 27s 3ms/step - loss: 0.3926 - acc: 0.8791 - val_loss: 0.4875 - val_acc: 0.8622\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 27s 3ms/step - loss: 0.4205 - acc: 0.8696 - val_loss: 0.5806 - val_acc: 0.8396\n",
      "Layer: -10\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.4525 - acc: 0.8581 - val_loss: 0.4230 - val_acc: 0.8638\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 29s 3ms/step - loss: 0.3722 - acc: 0.8844 - val_loss: 0.4089 - val_acc: 0.8776\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 29s 3ms/step - loss: 0.3775 - acc: 0.8856 - val_loss: 0.3738 - val_acc: 0.8997\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 29s 3ms/step - loss: 0.3774 - acc: 0.8847 - val_loss: 0.4901 - val_acc: 0.8371\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 29s 3ms/step - loss: 0.3419 - acc: 0.8970 - val_loss: 0.4112 - val_acc: 0.8981\n",
      "Layer: -11\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 33s 3ms/step - loss: 0.3734 - acc: 0.8885 - val_loss: 0.3799 - val_acc: 0.8801\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 31s 3ms/step - loss: 0.3328 - acc: 0.8983 - val_loss: 0.3429 - val_acc: 0.8997\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 31s 3ms/step - loss: 0.3321 - acc: 0.9078 - val_loss: 0.3360 - val_acc: 0.9014\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 30s 3ms/step - loss: 0.2630 - acc: 0.9202 - val_loss: 0.4367 - val_acc: 0.8789\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 30s 3ms/step - loss: 0.3275 - acc: 0.9022 - val_loss: 0.3526 - val_acc: 0.9077\n",
      "Layer: -12\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 35s 4ms/step - loss: 0.3694 - acc: 0.8952 - val_loss: 0.4848 - val_acc: 0.8396\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.2985 - acc: 0.9117 - val_loss: 0.3274 - val_acc: 0.8993\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.2764 - acc: 0.9198 - val_loss: 0.3437 - val_acc: 0.8981\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1940 - acc: 0.9406 - val_loss: 0.3175 - val_acc: 0.9219\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.2185 - acc: 0.9330 - val_loss: 0.2814 - val_acc: 0.9190\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.2442 - acc: 0.9315 - val_loss: 0.2674 - val_acc: 0.9240\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1629 - acc: 0.9479 - val_loss: 0.2650 - val_acc: 0.9252\n",
      "Epoch 8/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1625 - acc: 0.9462 - val_loss: 0.2307 - val_acc: 0.9353\n",
      "Epoch 9/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.3155 - acc: 0.9146 - val_loss: 0.4245 - val_acc: 0.8889\n",
      "Epoch 10/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1691 - acc: 0.9473 - val_loss: 0.2302 - val_acc: 0.9453\n",
      "Epoch 11/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1732 - acc: 0.9501 - val_loss: 0.2706 - val_acc: 0.9282\n",
      "Epoch 12/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1811 - acc: 0.9526 - val_loss: 0.2750 - val_acc: 0.9353\n",
      "Layer: -13\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 34s 4ms/step - loss: 0.1668 - acc: 0.9516 - val_loss: 0.2118 - val_acc: 0.9357\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1831 - acc: 0.9504 - val_loss: 0.4003 - val_acc: 0.9202\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1857 - acc: 0.9481 - val_loss: 0.1788 - val_acc: 0.9428\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 32s 3ms/step - loss: 0.1105 - acc: 0.9662 - val_loss: 0.2206 - val_acc: 0.9499\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 31s 3ms/step - loss: 0.3045 - acc: 0.9178 - val_loss: 0.2577 - val_acc: 0.9202\n",
      "Layer: -14\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 39s 4ms/step - loss: 0.1944 - acc: 0.9472 - val_loss: 0.3422 - val_acc: 0.9273\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 35s 4ms/step - loss: 0.1648 - acc: 0.9548 - val_loss: 0.2240 - val_acc: 0.9415\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 34s 4ms/step - loss: 0.1644 - acc: 0.9547 - val_loss: 0.3999 - val_acc: 0.9269\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 34s 4ms/step - loss: 0.2024 - acc: 0.9448 - val_loss: 0.2269 - val_acc: 0.9390\n",
      "Layer: -15\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 41s 4ms/step - loss: 0.1726 - acc: 0.9495 - val_loss: 0.2215 - val_acc: 0.9344\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 37s 4ms/step - loss: 0.1971 - acc: 0.9479 - val_loss: 0.2298 - val_acc: 0.9432\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 37s 4ms/step - loss: 0.1319 - acc: 0.9578 - val_loss: 0.3312 - val_acc: 0.9211\n",
      "Layer: -16\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 42s 4ms/step - loss: 0.1654 - acc: 0.9564 - val_loss: 0.2244 - val_acc: 0.9444\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 37s 4ms/step - loss: 0.2628 - acc: 0.9270 - val_loss: 0.2605 - val_acc: 0.9340\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 37s 4ms/step - loss: 0.1746 - acc: 0.9501 - val_loss: 0.2258 - val_acc: 0.9465\n",
      "Layer: -17\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 45s 5ms/step - loss: 0.2436 - acc: 0.9369 - val_loss: 0.3716 - val_acc: 0.9327\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 42s 4ms/step - loss: 0.1205 - acc: 0.9654 - val_loss: 0.2591 - val_acc: 0.9298\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 41s 4ms/step - loss: 0.1757 - acc: 0.9537 - val_loss: 0.2309 - val_acc: 0.9432\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 41s 4ms/step - loss: 0.1431 - acc: 0.9624 - val_loss: 0.2704 - val_acc: 0.9336\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 42s 4ms/step - loss: 0.0962 - acc: 0.9699 - val_loss: 0.2105 - val_acc: 0.9528\n",
      "Epoch 6/100\n",
      "9575/9575 [==============================] - 41s 4ms/step - loss: 0.1091 - acc: 0.9680 - val_loss: 0.2534 - val_acc: 0.9302\n",
      "Epoch 7/100\n",
      "9575/9575 [==============================] - 41s 4ms/step - loss: 0.1074 - acc: 0.9685 - val_loss: 0.2306 - val_acc: 0.9574\n",
      "Layer: -18\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 48s 5ms/step - loss: 0.2384 - acc: 0.9371 - val_loss: 0.2504 - val_acc: 0.9290\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9575/9575 [==============================] - 44s 5ms/step - loss: 0.1149 - acc: 0.9676 - val_loss: 0.2931 - val_acc: 0.9348\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 43s 5ms/step - loss: 0.0920 - acc: 0.9722 - val_loss: 0.2304 - val_acc: 0.9553\n",
      "Epoch 4/100\n",
      "9575/9575 [==============================] - 44s 5ms/step - loss: 0.0873 - acc: 0.9745 - val_loss: 0.2562 - val_acc: 0.9524\n",
      "Epoch 5/100\n",
      "9575/9575 [==============================] - 44s 5ms/step - loss: 0.0715 - acc: 0.9786 - val_loss: 0.3605 - val_acc: 0.9461\n",
      "Layer: -19\n",
      "Train on 9575 samples, validate on 2394 samples\n",
      "Epoch 1/100\n",
      "9575/9575 [==============================] - 48s 5ms/step - loss: 0.1391 - acc: 0.9675 - val_loss: 0.2191 - val_acc: 0.9382\n",
      "Epoch 2/100\n",
      "9575/9575 [==============================] - 43s 4ms/step - loss: 0.1718 - acc: 0.9587 - val_loss: 0.2778 - val_acc: 0.9403\n",
      "Epoch 3/100\n",
      "9575/9575 [==============================] - 44s 5ms/step - loss: 0.0719 - acc: 0.9791 - val_loss: 0.2568 - val_acc: 0.9536\n"
     ]
    }
   ],
   "source": [
    "w = list(range(-1,-20,-1))\n",
    "\n",
    "lr=.0001\n",
    "for i in w:\n",
    "    release_layers(i,lr)\n",
    "\n",
    "\n",
    "#release_layers(-20,.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_car_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_car_final.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "#load json and create model\n",
    "json_file = open('model_car_final.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_car_final.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9522218509856332"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "accuracy_score(y_test_encoded, y_pred_classes)\n",
    "#confusion_matrix(y_test_encoded, y_pred_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
