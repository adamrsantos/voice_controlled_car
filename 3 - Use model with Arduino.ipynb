{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect NN Model with Arduino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to process an audio file, classify it with the NN model, then send the resulting command to the arudino car to excecute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Send Command to Arduino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "# your Serial port should be different!\n",
    "#arduino = serial.Serial('/dev/cu.HC-06-SPPDev', 9600)\n",
    "\n",
    "def onOffFunction(command):\n",
    "    #arduino = serial.Serial('/dev/cu.HC-06-SPPDev', 9600)\n",
    "    #command = input(\"type go, stop, left, or right\")\n",
    "    if command ==\"go\":\n",
    "        #print(\"Forward\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('F')) \n",
    "        #onOffFunction()\n",
    "    elif command ==\"stop\":\n",
    "        #print(\"Stop\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('S'))\n",
    "        #onOffFunction()\n",
    "    elif command ==\"left\":\n",
    "        #print(\"Left\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('L'))\n",
    "        #onOffFunction()\n",
    "    elif command ==\"right\":\n",
    "        #print(\"Right\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('R'))\n",
    "        #onOffFunction()\n",
    "    elif command ==\"two\":\n",
    "        #print(\"Right\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('T'))\n",
    "        #onOffFunction()\n",
    "    elif command ==\"three\":\n",
    "        #print(\"Right\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('E'))\n",
    "        #onOffFunction()\n",
    "    elif command ==\"happy\":\n",
    "        #print(\"Right\")\n",
    "        #time.sleep(.01) \n",
    "        arduino.write(str.encode('H'))\n",
    "        #onOffFunction()\n",
    "    else:\n",
    "        print(\"No command recognized!\")\n",
    "\n",
    "#time.sleep(2) #waiting the initialization...\n",
    "\n",
    "#onOffFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "#load json and create model\n",
    "json_file = open('model_car_final.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_car_final.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to process sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield int(start), int(start + window_size)\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def process_sounds(signal,bands):\n",
    "    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "    \n",
    "    return logspec\n",
    "        \n",
    "\n",
    "def extract_features(fn,bands = 128, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    \n",
    "        \n",
    "    sound_clip,s = librosa.load(fn)\n",
    "\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            logspec = process_sounds(signal,bands)\n",
    "            log_specgrams.append(logspec)\n",
    "            #mfccs.append(logmfcc)\n",
    "            #labels.append(label)\n",
    "    \n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.array(log_specgrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get sound, process it, and run through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(sample):\n",
    "    test_sample = extract_features(sample)\n",
    "    print(test_sample.shape)\n",
    "    test_sample  = np.pad(test_sample, [(0, 0),(0, 0),(0, 7),(0, 2)], mode='constant', constant_values=0)\n",
    "    test_pred = loaded_model.predict(test_sample)\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cmd(pred):\n",
    "    ind = np.argmax(pred)\n",
    "    cmd = \"No command recognized\"\n",
    "    if pred[ind]>.92:\n",
    "        cmd = cmds[ind]\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "from collections import deque\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "LANG_CODE = 'en-US'  # Language to use\n",
    "\n",
    "GOOGLE_SPEECH_URL = 'https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&pfilter=2&lang=%s&maxresults=6' % (LANG_CODE)\n",
    "\n",
    "FLAC_CONV = 'flac -f'  # We need a WAV to FLAC converter. flac is available\n",
    "                       # on Linux\n",
    "\n",
    "# Microphone stream config.\n",
    "CHUNK = 1024  # CHUNKS of bytes to read each time from mic\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "THRESHOLD = 1200  # The threshold intensity that defines silence\n",
    "                  # and noise signal (an int. lower than THRESHOLD is silence).\n",
    "\n",
    "SILENCE_LIMIT = 1  # Silence limit in seconds. The max ammount of seconds where\n",
    "                   # only silence is recorded. When this time passes the\n",
    "                   # recording finishes and the file is delivered.\n",
    "\n",
    "PREV_AUDIO = .5  # Previous audio (in seconds) to prepend. When noise\n",
    "                  # is detected, how much of previously recorded audio is\n",
    "                  # prepended. This helps to prevent chopping the beggining\n",
    "                  # of the phrase.\n",
    "time_len=.5\n",
    "def listen_for_speech(threshold=THRESHOLD, num_phrases=-1):\n",
    "    \"\"\"\n",
    "    Listens to Microphone, extracts phrases from it and sends it to \n",
    "    Google's TTS service and returns response. a \"phrase\" is sound \n",
    "    surrounded by silence (according to threshold). num_phrases controls\n",
    "    how many phrases to process before finishing the listening process \n",
    "    (-1 for infinite). \n",
    "    \"\"\"\n",
    "\n",
    "    #Open stream\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"* Listening mic. \")\n",
    "    audio2send = []\n",
    "    cur_data = ''  # current chunk  of audio data\n",
    "    rel = int(RATE/CHUNK)\n",
    "    slid_win = deque(maxlen=SILENCE_LIMIT * rel)\n",
    "    #Prepend audio from 0.5 seconds before noise was detected\n",
    "    prev_audio = deque(maxlen=int(PREV_AUDIO * rel))\n",
    "    started = False\n",
    "    n = num_phrases\n",
    "    response = []\n",
    "\n",
    "    \n",
    "    \n",
    "    while (num_phrases == -1 or n > 0):\n",
    "        cur_data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "        slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))\n",
    "        #print slid_win[-1]\n",
    "        \n",
    "        tsum = sum([x > THRESHOLD for x in slid_win])\n",
    "        \n",
    "        if tsum > 0:\n",
    "            for i in range(0, int(RATE / CHUNK * time_len)):\n",
    "                data = stream.read(CHUNK)\n",
    "                audio2send.append(data)\n",
    "            slid_win = deque(maxlen=SILENCE_LIMIT * rel)\n",
    "            started=True\n",
    "        elif started == True:\n",
    "            # The limit was reached, finish capture and deliver.\n",
    "            \n",
    "            preds, filename = save_speech(list(prev_audio) +audio2send, p)\n",
    "            cmds = ['go','happy','left','right','stop','three','two']\n",
    "            cmd = 'No command recognized'\n",
    "            #print(preds)\n",
    "            #vfunc = np.vectorize(find_cmd)\n",
    "            #cmd = vfunc(preds)\n",
    "            for pred in preds:\n",
    "                ind = np.argmax(pred)\n",
    "                if pred[ind]>.92:\n",
    "                    cmd = cmds[ind]\n",
    "            print(cmd)\n",
    "            if cmd == 'three':\n",
    "                break\n",
    "            onOffFunction(cmd)\n",
    "            \n",
    "            # Send file to Model and get response\n",
    "            # Remove temp file. Comment line to review.\n",
    "            # Reset all\n",
    "            started = False\n",
    "            slid_win = deque(maxlen=int(SILENCE_LIMIT * rel))\n",
    "            prev_audio = deque(maxlen=1 * rel)\n",
    "            audio2send = []\n",
    "            n -= 1\n",
    "            \n",
    "            print (\"Listening ...\")\n",
    "        else:\n",
    "            prev_audio.append(cur_data)\n",
    "\n",
    "    print(\"* Done recording\")\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    return 'done'\n",
    "\n",
    "\n",
    "def save_speech(data, p):\n",
    "    \"\"\" Saves mic data to temporary WAV file. Returns filename of saved \n",
    "        file \"\"\"\n",
    "    \n",
    "    filename = 'Junk/output_'+str(int(time.time()))\n",
    "    # writes data to WAV file\n",
    "    data = b''.join(data)\n",
    "    wf = wave.open(filename + '.wav', 'wb')\n",
    "    wf.setnchannels(2)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(RATE)  # TODO make this value a function parameter?\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "    preds = model_output(filename + '.wav')\n",
    "    #print(preds)\n",
    "    return (preds,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excecute Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Listening mic. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-141574feeb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marduino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dev/cu.HC-06-SPPDev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlisten_for_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-ae11f87ef5f6>\u001b[0m in \u001b[0;36mlisten_for_speech\u001b[0;34m(threshold, num_phrases)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_phrases\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mcur_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexception_on_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mslid_win\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#print slid_win[-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "arduino = serial.Serial('/dev/cu.HC-06-SPPDev', 9600)\n",
    "listen_for_speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
